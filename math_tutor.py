import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.prompts import load_prompt
from langchain_core.output_parsers import StrOutputParser
import base64

load_dotenv()

st.title("ğŸ“¸ ì‚¬ê³ ë ¥ ê°•í™”í˜• AI ìˆ˜í•™ íŠœí„°")
st.write("ë¬¸ì œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜, ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì…ë ¥í•´ë³´ì„¸ìš”! ë‹¨ê³„ë³„ íŒíŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")

# --------------------------------------------------------
# ì„¸ì…˜ ì´ˆê¸°í™”
# --------------------------------------------------------
if "chat" not in st.session_state:
    st.session_state.chat = []

if "hint_step" not in st.session_state:
    st.session_state.hint_step = 0

# --------------------------------------------------------
# ëª¨ë¸ & YAML í”„ë¡¬í”„íŠ¸
# --------------------------------------------------------
model = ChatOpenAI(
    model="gpt-4o-mini",
    max_tokens=1024
)

prompt = load_prompt("./templates/math_tutor.yaml", encoding="utf-8")

parser = StrOutputParser()

# --------------------------------------------------------
# ì´ë¯¸ì§€ ì—…ë¡œë“œ + ë¯¸ë¦¬ë³´ê¸°
# --------------------------------------------------------
uploaded_file = st.file_uploader("ğŸ“· ë¬¸ì œ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["png", "jpg", "jpeg"])

base64_img = None
if uploaded_file:
    st.image(uploaded_file, caption="ğŸ“˜ ì—…ë¡œë“œí•œ ë¬¸ì œ ì´ë¯¸ì§€", use_column_width=True)
    base64_img = base64.b64encode(uploaded_file.read()).decode("utf-8")

# --------------------------------------------------------
# íŒíŠ¸ ë²„íŠ¼
# --------------------------------------------------------
st.write("### ğŸ” ì›í•˜ëŠ” ë„ì›€ì„ ì„ íƒí•˜ì„¸ìš”!")

col1, col2, col3 = st.columns(3)

with col1:
    if st.button("ğŸ‘¶ ì–´ë–»ê²Œ ì ‘ê·¼í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´ìš” (1ë‹¨ê³„ íŒíŠ¸)"):
        st.session_state.hint_step = 1

with col2:
    if st.button("ğŸ§  í•µì‹¬ ê°œë…ì´ ì•Œê³  ì‹¶ì–´ìš” (2ë‹¨ê³„ íŒíŠ¸)"):
        st.session_state.hint_step = 2

with col3:
    if st.button("ğŸš€ ê±°ì˜ ë‹¤ í’€ì—ˆì–´ìš”! ë§ˆì§€ë§‰ ë„ì›€! (3ë‹¨ê³„ íŒíŠ¸)"):
        st.session_state.hint_step = 3

# --------------------------------------------------------
# ëŒ€í™” ê¸°ë¡ ì¶œë ¥
# --------------------------------------------------------
for role, content in st.session_state.chat:
    st.chat_message(role).write(content)

# --------------------------------------------------------
# ì‚¬ìš©ì ì…ë ¥
# --------------------------------------------------------
user_text = st.chat_input("âœï¸ ì§ˆë¬¸ ë˜ëŠ” í’€ì´ë¥¼ ì…ë ¥í•˜ì„¸ìš”!")

if user_text or uploaded_file:

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
    st.session_state.chat.append(("user", user_text if user_text else "[ì´ë¯¸ì§€ ì—…ë¡œë“œë¨]"))

    # ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë©”ì‹œì§€ë¡œ êµ¬ì„±
    user_content = [
        {
            "type": "text",
            "text": f"íŒíŠ¸ ë‹¨ê³„: {st.session_state.hint_step}\ní•™ìƒ ì…ë ¥: {user_text}"
        }
    ]

    if base64_img:
        user_content.append({
            "type": "image_url",
            "image_url": {"url": f"data:image/png;base64,{base64_img}"}
        })

    # ëª¨ë¸ í˜¸ì¶œ
    response = model.invoke([
    {"role": "system", "content": prompt.template},   # ìˆ˜ì •ëœ ë¶€ë¶„
    {"role": "user", "content": user_content}
])

    answer = response.content

    # ê¸°ë¡ ì €ì¥
    st.session_state.chat.append(("assistant", answer))

    # ì¶œë ¥
    st.chat_message("assistant").write(answer)
